{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "516d92c8",
   "metadata": {},
   "source": [
    "### 2.2.1 创建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496fc5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先导入PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0f33b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0102e-38, 9.0919e-39, 1.0102e-38],\n",
      "        [8.9082e-39, 9.2755e-39, 1.0837e-38],\n",
      "        [8.4490e-39, 1.1112e-38, 1.0194e-38],\n",
      "        [9.0919e-39, 8.4490e-39, 9.6429e-39],\n",
      "        [8.4490e-39, 9.6429e-39, 9.2755e-39]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个5x3的未初始化的Tensor：\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aed7086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7285, 0.0815, 0.2594],\n",
      "        [0.5888, 0.4555, 0.7882],\n",
      "        [0.3437, 0.7168, 0.3832],\n",
      "        [0.4074, 0.1384, 0.3757],\n",
      "        [0.9963, 0.1289, 0.5599]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个5x3的随机初始化的Tensor:\n",
    "y = torch.rand(5, 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc18d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个5x3的long型全0的Tensor:\n",
    "z = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070acab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f77dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 通过现有的Tensor来创建，此方法会默认重用输入Tensor的一些属性，例如数据类型，除非自定义数据类型。\n",
    "x = x.new_ones(5, 3, dtype=torch.float64)  # 返回的tensor默认具有相同的torch.dtype和torch.device\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5bed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3964, -0.3068, -0.0438],\n",
      "        [-0.3694,  0.7346,  0.7118],\n",
      "        [-1.9267, -0.5269, -0.5103],\n",
      "        [ 0.9307, -1.0041, -0.5653],\n",
      "        [-0.2234, -0.6141, -0.5410]])\n"
     ]
    }
   ],
   "source": [
    "# 指定新的数据类型\n",
    "y = torch.randn_like(x, dtype=torch.float)\n",
    "print(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8abd89be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 可以通过shape或者size()来获取Tensor的形状:\n",
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189db67",
   "metadata": {},
   "source": [
    "### 2.2.2 操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed7a6bc",
   "metadata": {},
   "source": [
    "+ 算术操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628ca0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3007, 1.3105, 1.7530],\n",
      "        [1.2245, 1.8028, 1.5357],\n",
      "        [1.1721, 1.2505, 1.0169],\n",
      "        [1.1013, 1.1689, 1.8965],\n",
      "        [1.9866, 1.7678, 1.5752]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 加法形式一\n",
    "  y = torch.rand(5, 3)\n",
    "  print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbc4142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3007, 1.3105, 1.7530],\n",
      "        [1.2245, 1.8028, 1.5357],\n",
      "        [1.1721, 1.2505, 1.0169],\n",
      "        [1.1013, 1.1689, 1.8965],\n",
      "        [1.9866, 1.7678, 1.5752]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 加法形式二\n",
    "  print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "414f3c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3007, 1.3105, 1.7530],\n",
      "        [1.2245, 1.8028, 1.5357],\n",
      "        [1.1721, 1.2505, 1.0169],\n",
      "        [1.1013, 1.1689, 1.8965],\n",
      "        [1.9866, 1.7678, 1.5752]])\n"
     ]
    }
   ],
   "source": [
    "# 指定输出\n",
    "  result = torch.empty(5, 3)\n",
    "  torch.add(x, y, out=result)\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f37e0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3007, 1.3105, 1.7530],\n",
      "        [1.2245, 1.8028, 1.5357],\n",
      "        [1.1721, 1.2505, 1.0169],\n",
      "        [1.1013, 1.1689, 1.8965],\n",
      "        [1.9866, 1.7678, 1.5752]])\n"
     ]
    }
   ],
   "source": [
    "# 加法形式三、inplace\n",
    "# adds x to y\n",
    "  y.add_(x)\n",
    "  print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e9278c",
   "metadata": {},
   "source": [
    "+ 索引\n",
    "+ 索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5952a320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2.], dtype=torch.float64)\n",
      "tensor([2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = x[0, :]\n",
    "y += 1\n",
    "print(y)\n",
    "print(x[0, :]) # 源tensor也被改了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14dcf6e",
   "metadata": {},
   "source": [
    "+ 改变形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78c9e624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "# 用view()来改变Tensor的形状：\n",
    "y = x.view(15)\n",
    "z = x.view(-1, 5)  # -1所指的维度可以根据其他维度的值推出来\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd34234",
   "metadata": {},
   "source": [
    "view()返回的新Tensor与源Tensor虽然可能有不同的size，但是是共享data的，也即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的观察角度，内部数据并未改变)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1aaa21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]], dtype=torch.float64)\n",
      "tensor([3., 3., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x += 1\n",
    "print(x)\n",
    "print(y) # 也加了1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6446a",
   "metadata": {},
   "source": [
    "如果想返回一个真正新的副本（不共享data内存），先用clone创造一个副本然后再使用view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c4a86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([3., 3., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x_cp = x.clone().view(15)\n",
    "x -= 1\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3519c",
   "metadata": {},
   "source": [
    "使用clone还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63b1f2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4747])\n",
      "0.4746860861778259\n"
     ]
    }
   ],
   "source": [
    "# item(), 它可以将一个标量Tensor转换成一个Python number\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7138e4",
   "metadata": {},
   "source": [
    "### 2.2.3 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4caf3703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "# 当对两个形状不同的Tensor按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个Tensor形状相同后再按元素运算。例如\n",
    "x = torch.arange(1, 3).view(1, 2)\n",
    "print(x)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "print(y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a09dbd",
   "metadata": {},
   "source": [
    "由于x和y分别是1行2列和3行1列的矩阵，如果要计算x + y，那么x中第一行的2个元素被广播（复制）到了第二行和第三行，而y中第一列的3个元素被广播（复制）到了第二列。如此，就可以对2个3行2列的矩阵按元素相加。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14886e71",
   "metadata": {},
   "source": [
    "### 2.2.4 运算的内存开销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "542d4240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# 索引操作不会开辟新内存，而像y = x + y这样的运算会新开内存，然后将y指向新内存。\n",
    "# 使用Python自带的id函数来演示：如果两个实例的ID一致，那么它们所对应的内存地址相同；反之则不同。\n",
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "y = y + x\n",
    "print(id(y) == id_before) # False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c542974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 如果想指定结果到原来的y的内存，可以使用前面介绍的索引来进行替换操作。\n",
    "# 把x + y的结果通过[:]写进y对应的内存中。\n",
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "y[:] = y + x\n",
    "print(id(y) == id_before) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a15037d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 还可以使用运算符全名函数中的out参数或者自加运算符+=(也即add_())达到上述效果，例如torch.add(x, y, out=y)和y += x(y.add_(x))\n",
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "torch.add(x, y, out=y) # y += x, y.add_(x)\n",
    "print(id(y) == id_before) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e510869",
   "metadata": {},
   "source": [
    "虽然view返回的Tensor与源Tensor是共享data的，但是依然是一个新的Tensor（因为Tensor除了包含data外还有一些其他属性），二者id（内存地址）并不一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d9a75",
   "metadata": {},
   "source": [
    "### 2.2.5 Tensor和NumPy相互转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf77475",
   "metadata": {},
   "source": [
    "用numpy()和from_numpy()可以将Tensor和NumPy中的数组相互转换。\n",
    "但是这两个函数所产生的的Tensor和NumPy中的数组共享相同的内存（所以他们之间的转换很快），改变其中一个时另一个也会改变！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340144ab",
   "metadata": {},
   "source": [
    "+ Tensor转NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4c19239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n",
      "tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# 使用numpy()将Tensor转换成NumPy数组\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, b)\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5902f3",
   "metadata": {},
   "source": [
    "+ NumPy数组转Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82f91a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 使用from_numpy()将NumPy数组转换成Tensor\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, b)\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70ec3a",
   "metadata": {},
   "source": [
    "所有在CPU上的Tensor（除了CharTensor）都支持与NumPy数组相互转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0982b1d",
   "metadata": {},
   "source": [
    "另一个常用的将NumPy中的array转换成Tensor的方法是torch.tensor()。\n",
    "但此方法总是会进行数据拷贝（消耗更多的时间和空间），所以返回的Tensor和原来的数据不再共享内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29e348",
   "metadata": {},
   "source": [
    "+ torch.tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb22552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor(a)\n",
    "a += 1\n",
    "print(a, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad6fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7abb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da035213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf2631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0efeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823335e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6308e3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
